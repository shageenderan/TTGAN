{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "timegan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zOpZi68sdb_",
        "colab_type": "text"
      },
      "source": [
        "# Timegan Synthetic Data Generation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzD83rr1uwQl",
        "colab_type": "code",
        "outputId": "8810b99b-5871-4904-df6b-7f86b2b34b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# # %tensorflow_version 1.x\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0, 1\"  # or even \"-1\" for only cpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxfGWinCsdb_",
        "colab_type": "text"
      },
      "source": [
        "## TimeGAN Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUiD1e0JsdcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utils\n",
        "def extract_time (data):\n",
        "  \"\"\"Returns Maximum sequence length and each sequence length.\n",
        "  \n",
        "  Args:\n",
        "    - data: original data\n",
        "    \n",
        "  Returns:\n",
        "    - time: extracted time information\n",
        "    - max_seq_len: maximum sequence length\n",
        "  \"\"\"\n",
        "  time = list()\n",
        "  max_seq_len = 0\n",
        "  for i in range(len(data)):\n",
        "    max_seq_len = max(max_seq_len, len(data[i][:,0]))\n",
        "    time.append(len(data[i][:,0]))\n",
        "    \n",
        "  return time, max_seq_len\n",
        "\n",
        "\n",
        "def rnn_cell(module_name, hidden_dim):\n",
        "  \"\"\"Basic RNN Cell.\n",
        "    \n",
        "  Args:\n",
        "    - module_name: gru, lstm, or lstmLN\n",
        "    \n",
        "  Returns:\n",
        "    - rnn_cell: RNN Cell\n",
        "  \"\"\"\n",
        "  assert module_name in ['gru','lstm','lstmLN']\n",
        "  \n",
        "  # GRU\n",
        "  if (module_name == 'gru'):\n",
        "    rnn_cell = tf.nn.rnn_cell.GRUCell(num_units=hidden_dim, activation=tf.nn.tanh)\n",
        "  # LSTM\n",
        "  elif (module_name == 'lstm'):\n",
        "    rnn_cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_dim, activation=tf.nn.tanh)\n",
        "  # LSTM Layer Normalization\n",
        "  elif (module_name == 'lstmLN'):\n",
        "    rnn_cell = tf.contrib.rnn.LayerNormBasicLSTMCell(num_units=hidden_dim, activation=tf.nn.tanh)\n",
        "  return rnn_cell\n",
        "\n",
        "\n",
        "def random_generator (batch_size, z_dim, T_mb, max_seq_len):\n",
        "  \"\"\"Random vector generation.\n",
        "  \n",
        "  Args:\n",
        "    - batch_size: size of the random vector\n",
        "    - z_dim: dimension of random vector\n",
        "    - T_mb: time information for the random vector\n",
        "    - max_seq_len: maximum sequence length\n",
        "    \n",
        "  Returns:\n",
        "    - Z_mb: generated random vector\n",
        "  \"\"\"\n",
        "  Z_mb = list()\n",
        "  for i in range(batch_size):\n",
        "    temp = np.zeros([max_seq_len, z_dim])\n",
        "    temp_Z = np.random.uniform(0., 1, [T_mb[i], z_dim])\n",
        "    temp[:T_mb[i],:] = temp_Z\n",
        "    Z_mb.append(temp_Z)\n",
        "  # print(\"ZSHAPE:\", np.shape(Z_mb))\n",
        "  return Z_mb\n",
        "\n",
        "\n",
        "def batch_generator(data, time, batch_size):\n",
        "  \"\"\"Mini-batch generator.\n",
        "  \n",
        "  Args:\n",
        "    - data: time-series data\n",
        "    - time: time information\n",
        "    - batch_size: the number of samples in each batch\n",
        "    \n",
        "  Returns:\n",
        "    - X_mb: time-series data in each batch\n",
        "    - T_mb: time information in each batch\n",
        "  \"\"\"\n",
        "  no = len(data)\n",
        "  idx = np.random.permutation(no)\n",
        "  train_idx = idx[:batch_size]     \n",
        "            \n",
        "  X_mb = list(data[i] for i in train_idx)\n",
        "  T_mb = list(time[i] for i in train_idx)\n",
        "  \n",
        "  return X_mb, T_mb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDD-aFgPsdcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Necessary Packages\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def timegan_train(ori_data, parameters):\n",
        "  \"\"\"TimeGAN function.\n",
        "  \n",
        "  Use original data as training set to generater synthetic data (time-series)\n",
        "  \n",
        "  Args:\n",
        "    - ori_data: original time-series data\n",
        "    - parameters: TimeGAN network parameters\n",
        "    \n",
        "  Returns:\n",
        "    - generated_data: generated time-series data\n",
        "  \"\"\"\n",
        "  # Initialization on the Graph\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  # Basic Parameters\n",
        "  no, seq_len, dim = np.asarray(ori_data).shape\n",
        "    \n",
        "  # Maximum sequence length and each sequence length\n",
        "  ori_time, max_seq_len = extract_time(ori_data)\n",
        "  \n",
        "  def MinMaxScaler(data):\n",
        "    \"\"\"Min-Max Normalizer.\n",
        "    \n",
        "    Args:\n",
        "      - data: raw data\n",
        "      \n",
        "    Returns:\n",
        "      - norm_data: normalized data\n",
        "      - min_val: minimum values (for renormalization)\n",
        "      - max_val: maximum values (for renormalization)\n",
        "    \"\"\"    \n",
        "    min_val = np.min(np.min(data, axis = 0), axis = 0)\n",
        "    data = data - min_val\n",
        "      \n",
        "    max_val = np.max(np.max(data, axis = 0), axis = 0)\n",
        "    norm_data = data / (max_val + 1e-7)\n",
        "      \n",
        "    return norm_data, min_val, max_val\n",
        "  \n",
        "  # Normalization\n",
        "  ori_data, min_val, max_val = MinMaxScaler(ori_data)\n",
        "              \n",
        "  ## Build a RNN networks          \n",
        "  \n",
        "  # Network Parameters\n",
        "  hidden_dim   = parameters['hidden_dim'] \n",
        "  num_layers   = parameters['num_layer']\n",
        "  iterations   = parameters['iterations']\n",
        "  batch_size   = parameters['batch_size']\n",
        "  module_name  = parameters['module'] \n",
        "  z_dim        = dim\n",
        "  gamma        = 1\n",
        "    \n",
        "  # Input place holders\n",
        "  X = tf.placeholder(tf.float32, [None, max_seq_len, dim], name = \"myinput_x\")\n",
        "  Z = tf.placeholder(tf.float32, [None, max_seq_len, z_dim], name = \"myinput_z\")\n",
        "  T = tf.placeholder(tf.int32, [None], name = \"myinput_t\")\n",
        "  \n",
        "  def embedder (X, T):\n",
        "    \"\"\"Embedding network between original feature space to latent space.\n",
        "    \n",
        "    Args:\n",
        "      - X: input time-series features\n",
        "      - T: input time information\n",
        "      \n",
        "    Returns:\n",
        "      - H: embeddings\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(\"embedder\", reuse = tf.AUTO_REUSE):\n",
        "      e_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers)])\n",
        "      e_outputs, e_last_states = tf.nn.dynamic_rnn(e_cell, X, dtype=tf.float32, sequence_length = T)\n",
        "      H = tf.contrib.layers.fully_connected(e_outputs, hidden_dim, activation_fn=tf.nn.sigmoid)     \n",
        "    return H\n",
        "      \n",
        "  def recovery (H, T):   \n",
        "    \"\"\"Recovery network from latent space to original space.\n",
        "    \n",
        "    Args:\n",
        "      - H: latent representation\n",
        "      - T: input time information\n",
        "      \n",
        "    Returns:\n",
        "      - X_tilde: recovered data\n",
        "    \"\"\"     \n",
        "    with tf.variable_scope(\"recovery\", reuse = tf.AUTO_REUSE):       \n",
        "      r_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers)])\n",
        "      r_outputs, r_last_states = tf.nn.dynamic_rnn(r_cell, H, dtype=tf.float32, sequence_length = T)\n",
        "      X_tilde = tf.contrib.layers.fully_connected(r_outputs, dim, activation_fn=tf.nn.sigmoid) \n",
        "    return X_tilde\n",
        "    \n",
        "  def generator (Z, T):  \n",
        "    \"\"\"Generator function: Generate time-series data in latent space.\n",
        "    \n",
        "    Args:\n",
        "      - Z: random variables\n",
        "      - T: input time information\n",
        "      \n",
        "    Returns:\n",
        "      - E: generated embedding\n",
        "    \"\"\"        \n",
        "    with tf.variable_scope(\"generator\", reuse = tf.AUTO_REUSE):\n",
        "      e_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers)])\n",
        "      e_outputs, e_last_states = tf.nn.dynamic_rnn(e_cell, Z, dtype=tf.float32, sequence_length = T)\n",
        "      E = tf.contrib.layers.fully_connected(e_outputs, hidden_dim, activation_fn=tf.nn.sigmoid)     \n",
        "    return E\n",
        "      \n",
        "  def supervisor (H, T): \n",
        "    \"\"\"Generate next sequence using the previous sequence.\n",
        "    \n",
        "    Args:\n",
        "      - H: latent representation\n",
        "      - T: input time information\n",
        "      \n",
        "    Returns:\n",
        "      - S: generated sequence based on the latent representations generated by the generator\n",
        "    \"\"\"          \n",
        "    with tf.variable_scope(\"supervisor\", reuse = tf.AUTO_REUSE):\n",
        "      e_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers-1)])\n",
        "      e_outputs, e_last_states = tf.nn.dynamic_rnn(e_cell, H, dtype=tf.float32, sequence_length = T)\n",
        "      S = tf.contrib.layers.fully_connected(e_outputs, hidden_dim, activation_fn=tf.nn.sigmoid)     \n",
        "    return S\n",
        "          \n",
        "  def discriminator (H, T):\n",
        "    \"\"\"Discriminate the original and synthetic time-series data.\n",
        "    \n",
        "    Args:\n",
        "      - H: latent representation\n",
        "      - T: input time information\n",
        "      \n",
        "    Returns:\n",
        "      - Y_hat: classification results between original and synthetic time-series\n",
        "    \"\"\"        \n",
        "    with tf.variable_scope(\"discriminator\", reuse = tf.AUTO_REUSE):\n",
        "      d_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers)])\n",
        "      d_outputs, d_last_states = tf.nn.dynamic_rnn(d_cell, H, dtype=tf.float32, sequence_length = T)\n",
        "      Y_hat = tf.contrib.layers.fully_connected(d_outputs, 1, activation_fn=None) \n",
        "    return Y_hat   \n",
        "    \n",
        "  # Embedder & Recovery\n",
        "  H = embedder(X, T)\n",
        "  X_tilde = recovery(H, T)\n",
        "    \n",
        "  # Generator\n",
        "  E_hat = generator(Z, T)\n",
        "  H_hat = supervisor(E_hat, T)\n",
        "  H_hat_supervise = supervisor(H, T)\n",
        "    \n",
        "  # Synthetic data\n",
        "  X_hat = recovery(H_hat, T)\n",
        "    \n",
        "  # Discriminator\n",
        "  Y_fake = discriminator(H_hat, T)\n",
        "  Y_real = discriminator(H, T)     \n",
        "  Y_fake_e = discriminator(E_hat, T)\n",
        "    \n",
        "  # Variables        \n",
        "  e_vars = [v for v in tf.trainable_variables() if v.name.startswith('embedder')]\n",
        "  r_vars = [v for v in tf.trainable_variables() if v.name.startswith('recovery')]\n",
        "  g_vars = [v for v in tf.trainable_variables() if v.name.startswith('generator')]\n",
        "  s_vars = [v for v in tf.trainable_variables() if v.name.startswith('supervisor')]\n",
        "  d_vars = [v for v in tf.trainable_variables() if v.name.startswith('discriminator')]\n",
        "    \n",
        "  # Discriminator loss\n",
        "  D_loss_real = tf.losses.sigmoid_cross_entropy(tf.ones_like(Y_real), Y_real)\n",
        "  D_loss_fake = tf.losses.sigmoid_cross_entropy(tf.zeros_like(Y_fake), Y_fake)\n",
        "  D_loss_fake_e = tf.losses.sigmoid_cross_entropy(tf.zeros_like(Y_fake_e), Y_fake_e)\n",
        "  D_loss = D_loss_real + D_loss_fake + gamma * D_loss_fake_e\n",
        "            \n",
        "  # Generator loss\n",
        "  # 1. Adversarial loss\n",
        "  G_loss_U = tf.losses.sigmoid_cross_entropy(tf.ones_like(Y_fake), Y_fake)\n",
        "  G_loss_U_e = tf.losses.sigmoid_cross_entropy(tf.ones_like(Y_fake_e), Y_fake_e)\n",
        "    \n",
        "  # 2. Supervised loss\n",
        "  G_loss_S = tf.losses.mean_squared_error(H[:,1:,:], H_hat_supervise[:,1:,:])\n",
        "    \n",
        "  # 3. Two Momments\n",
        "  G_loss_V1 = tf.reduce_mean(tf.abs(tf.sqrt(tf.nn.moments(X_hat,[0])[1] + 1e-6) - tf.sqrt(tf.nn.moments(X,[0])[1] + 1e-6)))\n",
        "  G_loss_V2 = tf.reduce_mean(tf.abs((tf.nn.moments(X_hat,[0])[0]) - (tf.nn.moments(X,[0])[0])))\n",
        "    \n",
        "  G_loss_V = G_loss_V1 + G_loss_V2\n",
        "    \n",
        "  # 4. Summation\n",
        "  G_loss = G_loss_U + gamma * G_loss_U_e + 100 * tf.sqrt(G_loss_S) + 100*G_loss_V \n",
        "            \n",
        "  # Embedder network loss\n",
        "  E_loss_T0 = tf.losses.mean_squared_error(X, X_tilde)\n",
        "  E_loss0 = 10*tf.sqrt(E_loss_T0)\n",
        "  E_loss = E_loss0  + 0.1*G_loss_S\n",
        "    \n",
        "  # optimizer\n",
        "  E0_solver = tf.train.AdamOptimizer().minimize(E_loss0, var_list = e_vars + r_vars)\n",
        "  E_solver = tf.train.AdamOptimizer().minimize(E_loss, var_list = e_vars + r_vars)\n",
        "  D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list = d_vars)\n",
        "  G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list = g_vars + s_vars)      \n",
        "  GS_solver = tf.train.AdamOptimizer().minimize(G_loss_S, var_list = g_vars + s_vars)   \n",
        "        \n",
        "  ## TimeGAN training   \n",
        "  sess = tf.Session()\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "  # 1. Embedding network training\n",
        "  print('Start Embedding Network Training')\n",
        "    \n",
        "  for itt in range(iterations):\n",
        "    # Set mini-batch\n",
        "    X_mb, T_mb = batch_generator(ori_data, ori_time, batch_size)           \n",
        "    # Train embedder        \n",
        "    _, step_e_loss = sess.run([E0_solver, E_loss_T0], feed_dict={X: X_mb, T: T_mb})        \n",
        "    # Checkpoint\n",
        "    if itt % 100 == 0:\n",
        "      print('step: '+ str(itt) + '/' + str(iterations) + ', e_loss: ' + str(np.round(np.sqrt(step_e_loss),4)) ) \n",
        "      \n",
        "  print('Finish Embedding Network Training')\n",
        "    \n",
        "  # 2. Training only with supervised loss\n",
        "  print('Start Training with Supervised Loss Only')\n",
        "    \n",
        "  for itt in range(iterations):\n",
        "    # Set mini-batch\n",
        "    X_mb, T_mb = batch_generator(ori_data, ori_time, batch_size)    \n",
        "    # Random vector generation   \n",
        "    Z_mb = random_generator(batch_size, z_dim, T_mb, max_seq_len)\n",
        "    # Train generator       \n",
        "    _, step_g_loss_s = sess.run([GS_solver, G_loss_S], feed_dict={Z: Z_mb, X: X_mb, T: T_mb})       \n",
        "    # Checkpoint\n",
        "    if itt % 100 == 0:\n",
        "      print('step: '+ str(itt)  + '/' + str(iterations) +', s_loss: ' + str(np.round(np.sqrt(step_g_loss_s),4)) )\n",
        "      \n",
        "  print('Finish Training with Supervised Loss Only')\n",
        "    \n",
        "  # 3. Joint Training\n",
        "  print('Start Joint Training')\n",
        "  \n",
        "  for itt in range(iterations):\n",
        "    # Generator training (twice more than discriminator training)\n",
        "    for kk in range(2):\n",
        "      # Set mini-batch\n",
        "      X_mb, T_mb = batch_generator(ori_data, ori_time, batch_size)               \n",
        "      # Random vector generation\n",
        "      Z_mb = random_generator(batch_size, z_dim, T_mb, max_seq_len)\n",
        "      # Train generator\n",
        "      _, step_g_loss_u, step_g_loss_s, step_g_loss_v = sess.run([G_solver, G_loss_U, G_loss_S, G_loss_V], feed_dict={Z: Z_mb, X: X_mb, T: T_mb})\n",
        "       # Train embedder        \n",
        "      _, step_e_loss_t0 = sess.run([E_solver, E_loss_T0], feed_dict={Z: Z_mb, X: X_mb, T: T_mb})   \n",
        "           \n",
        "    # Discriminator training        \n",
        "    # Set mini-batch\n",
        "    X_mb, T_mb = batch_generator(ori_data, ori_time, batch_size)           \n",
        "    # Random vector generation\n",
        "    Z_mb = random_generator(batch_size, z_dim, T_mb, max_seq_len)\n",
        "    # Check discriminator loss before updating\n",
        "    check_d_loss = sess.run(D_loss, feed_dict={X: X_mb, T: T_mb, Z: Z_mb})\n",
        "    # Train discriminator (only when the discriminator does not work well)\n",
        "    if (check_d_loss > 0.15):        \n",
        "      _, step_d_loss = sess.run([D_solver, D_loss], feed_dict={X: X_mb, T: T_mb, Z: Z_mb})\n",
        "        \n",
        "    # Print multiple checkpoints\n",
        "    if itt % 100 == 0:\n",
        "      print('step: '+ str(itt) + '/' + str(iterations) + \n",
        "            ', d_loss: ' + str(np.round(step_d_loss,4)) + \n",
        "            ', g_loss_u: ' + str(np.round(step_g_loss_u,4)) + \n",
        "            ', g_loss_s: ' + str(np.round(np.sqrt(step_g_loss_s),4)) + \n",
        "            ', g_loss_v: ' + str(np.round(step_g_loss_v,4)) + \n",
        "            ', e_loss_t0: ' + str(np.round(np.sqrt(step_e_loss_t0),4))  )\n",
        "  print('Finish Joint Training')\n",
        "\n",
        "  # Save session\n",
        "  saver = tf.train.Saver()\n",
        "  save_path = saver.save(sess, os.path.join(OUTPUT_DIR, 'sess.ckpt'))\n",
        "\n",
        "def timegan_generate(parameters):\n",
        "  \"\"\"TimeGAN function.\n",
        "  \n",
        "  Use original data as training set to generater synthetic data (time-series)\n",
        "  \n",
        "  Args:\n",
        "    - ori_data: original time-series data\n",
        "    - parameters: TimeGAN network parameters\n",
        "    \n",
        "  Returns:\n",
        "    - generated_data: generated time-series data\n",
        "  \"\"\"\n",
        "  # Initialization on the Graph\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  # Get ori data\n",
        "  ori_data = soro_freemotion_data_loading(parameters['seq_length'] )\n",
        "\n",
        "  # Basic Parameters\n",
        "  no, seq_len, dim = np.asarray(ori_data).shape\n",
        "    \n",
        "  # Maximum sequence length and each sequence length\n",
        "  ori_time, max_seq_len = extract_time(ori_data)\n",
        "  \n",
        "  def MinMaxScaler(data):\n",
        "    \"\"\"Min-Max Normalizer.\n",
        "    \n",
        "    Args:\n",
        "      - data: raw data\n",
        "      \n",
        "    Returns:\n",
        "      - norm_data: normalized data\n",
        "      - min_val: minimum values (for renormalization)\n",
        "      - max_val: maximum values (for renormalization)\n",
        "    \"\"\"    \n",
        "    min_val = np.min(np.min(data, axis = 0), axis = 0)\n",
        "    data = data - min_val\n",
        "      \n",
        "    max_val = np.max(np.max(data, axis = 0), axis = 0)\n",
        "    norm_data = data / (max_val + 1e-7)\n",
        "      \n",
        "    return norm_data, min_val, max_val\n",
        "  \n",
        "  # Normalization\n",
        "  ori_data, min_val, max_val = MinMaxScaler(ori_data)\n",
        "              \n",
        "  ## Build a RNN networks          \n",
        "  \n",
        "  # Network Parameters\n",
        "  hidden_dim   = parameters['hidden_dim'] \n",
        "  num_layers   = parameters['num_layer']\n",
        "  iterations   = parameters['iterations']\n",
        "  batch_size   = parameters['batch_size']\n",
        "  module_name  = parameters['module'] \n",
        "  z_dim        = dim\n",
        "  gamma        = 1\n",
        "    \n",
        "  # Input place holders\n",
        "  X = tf.placeholder(tf.float32, [None, max_seq_len, dim], name = \"myinput_x\")\n",
        "  Z = tf.placeholder(tf.float32, [None, max_seq_len, z_dim], name = \"myinput_z\")\n",
        "  T = tf.placeholder(tf.int32, [None], name = \"myinput_t\")\n",
        "  \n",
        "  def embedder (X, T):\n",
        "    \"\"\"Embedding network between original feature space to latent space.\n",
        "    \n",
        "    Args:\n",
        "      - X: input time-series features\n",
        "      - T: input time information\n",
        "      \n",
        "    Returns:\n",
        "      - H: embeddings\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(\"embedder\", reuse = tf.AUTO_REUSE):\n",
        "      e_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers)])\n",
        "      e_outputs, e_last_states = tf.nn.dynamic_rnn(e_cell, X, dtype=tf.float32, sequence_length = T)\n",
        "      H = tf.contrib.layers.fully_connected(e_outputs, hidden_dim, activation_fn=tf.nn.sigmoid)     \n",
        "    return H\n",
        "      \n",
        "  def recovery (H, T):   \n",
        "    \"\"\"Recovery network from latent space to original space.\n",
        "    \n",
        "    Args:\n",
        "      - H: latent representation\n",
        "      - T: input time information\n",
        "      \n",
        "    Returns:\n",
        "      - X_tilde: recovered data\n",
        "    \"\"\"     \n",
        "    with tf.variable_scope(\"recovery\", reuse = tf.AUTO_REUSE):       \n",
        "      r_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers)])\n",
        "      r_outputs, r_last_states = tf.nn.dynamic_rnn(r_cell, H, dtype=tf.float32, sequence_length = T)\n",
        "      X_tilde = tf.contrib.layers.fully_connected(r_outputs, dim, activation_fn=tf.nn.sigmoid) \n",
        "    return X_tilde\n",
        "    \n",
        "  def generator (Z, T):  \n",
        "    \"\"\"Generator function: Generate time-series data in latent space.\n",
        "    \n",
        "    Args:\n",
        "      - Z: random variables\n",
        "      - T: input time information\n",
        "      \n",
        "    Returns:\n",
        "      - E: generated embedding\n",
        "    \"\"\"        \n",
        "    with tf.variable_scope(\"generator\", reuse = tf.AUTO_REUSE):\n",
        "      e_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers)])\n",
        "      e_outputs, e_last_states = tf.nn.dynamic_rnn(e_cell, Z, dtype=tf.float32, sequence_length = T)\n",
        "      E = tf.contrib.layers.fully_connected(e_outputs, hidden_dim, activation_fn=tf.nn.sigmoid)     \n",
        "    return E\n",
        "      \n",
        "  def supervisor (H, T): \n",
        "    \"\"\"Generate next sequence using the previous sequence.\n",
        "    \n",
        "    Args:\n",
        "      - H: latent representation\n",
        "      - T: input time information\n",
        "      \n",
        "    Returns:\n",
        "      - S: generated sequence based on the latent representations generated by the generator\n",
        "    \"\"\"          \n",
        "    with tf.variable_scope(\"supervisor\", reuse = tf.AUTO_REUSE):\n",
        "      e_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers-1)])\n",
        "      e_outputs, e_last_states = tf.nn.dynamic_rnn(e_cell, H, dtype=tf.float32, sequence_length = T)\n",
        "      S = tf.contrib.layers.fully_connected(e_outputs, hidden_dim, activation_fn=tf.nn.sigmoid)     \n",
        "    return S\n",
        "          \n",
        "  def discriminator (H, T):\n",
        "    \"\"\"Discriminate the original and synthetic time-series data.\n",
        "    \n",
        "    Args:\n",
        "      - H: latent representation\n",
        "      - T: input time information\n",
        "      \n",
        "    Returns:\n",
        "      - Y_hat: classification results between original and synthetic time-series\n",
        "    \"\"\"        \n",
        "    with tf.variable_scope(\"discriminator\", reuse = tf.AUTO_REUSE):\n",
        "      d_cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(module_name, hidden_dim) for _ in range(num_layers)])\n",
        "      d_outputs, d_last_states = tf.nn.dynamic_rnn(d_cell, H, dtype=tf.float32, sequence_length = T)\n",
        "      Y_hat = tf.contrib.layers.fully_connected(d_outputs, 1, activation_fn=None) \n",
        "    return Y_hat   \n",
        "    \n",
        "  # Embedder & Recovery\n",
        "  H = embedder(X, T)\n",
        "  X_tilde = recovery(H, T)\n",
        "    \n",
        "  # Generator\n",
        "  E_hat = generator(Z, T)\n",
        "  H_hat = supervisor(E_hat, T)\n",
        "  H_hat_supervise = supervisor(H, T)\n",
        "    \n",
        "  # Synthetic data\n",
        "  X_hat = recovery(H_hat, T)\n",
        "    \n",
        "  # Discriminator\n",
        "  Y_fake = discriminator(H_hat, T)\n",
        "  Y_real = discriminator(H, T)     \n",
        "  Y_fake_e = discriminator(E_hat, T)\n",
        "    \n",
        "  # Variables        \n",
        "  e_vars = [v for v in tf.trainable_variables() if v.name.startswith('embedder')]\n",
        "  r_vars = [v for v in tf.trainable_variables() if v.name.startswith('recovery')]\n",
        "  g_vars = [v for v in tf.trainable_variables() if v.name.startswith('generator')]\n",
        "  s_vars = [v for v in tf.trainable_variables() if v.name.startswith('supervisor')]\n",
        "  d_vars = [v for v in tf.trainable_variables() if v.name.startswith('discriminator')]\n",
        "    \n",
        "  # Discriminator loss\n",
        "  D_loss_real = tf.losses.sigmoid_cross_entropy(tf.ones_like(Y_real), Y_real)\n",
        "  D_loss_fake = tf.losses.sigmoid_cross_entropy(tf.zeros_like(Y_fake), Y_fake)\n",
        "  D_loss_fake_e = tf.losses.sigmoid_cross_entropy(tf.zeros_like(Y_fake_e), Y_fake_e)\n",
        "  D_loss = D_loss_real + D_loss_fake + gamma * D_loss_fake_e\n",
        "            \n",
        "  # Generator loss\n",
        "  # 1. Adversarial loss\n",
        "  G_loss_U = tf.losses.sigmoid_cross_entropy(tf.ones_like(Y_fake), Y_fake)\n",
        "  G_loss_U_e = tf.losses.sigmoid_cross_entropy(tf.ones_like(Y_fake_e), Y_fake_e)\n",
        "    \n",
        "  # 2. Supervised loss\n",
        "  G_loss_S = tf.losses.mean_squared_error(H[:,1:,:], H_hat_supervise[:,1:,:])\n",
        "    \n",
        "  # 3. Two Momments\n",
        "  G_loss_V1 = tf.reduce_mean(tf.abs(tf.sqrt(tf.nn.moments(X_hat,[0])[1] + 1e-6) - tf.sqrt(tf.nn.moments(X,[0])[1] + 1e-6)))\n",
        "  G_loss_V2 = tf.reduce_mean(tf.abs((tf.nn.moments(X_hat,[0])[0]) - (tf.nn.moments(X,[0])[0])))\n",
        "    \n",
        "  G_loss_V = G_loss_V1 + G_loss_V2\n",
        "    \n",
        "  # 4. Summation\n",
        "  G_loss = G_loss_U + gamma * G_loss_U_e + 100 * tf.sqrt(G_loss_S) + 100*G_loss_V \n",
        "            \n",
        "  # Embedder network loss\n",
        "  E_loss_T0 = tf.losses.mean_squared_error(X, X_tilde)\n",
        "  E_loss0 = 10*tf.sqrt(E_loss_T0)\n",
        "  E_loss = E_loss0  + 0.1*G_loss_S\n",
        "    \n",
        "  # optimizer\n",
        "  E0_solver = tf.train.AdamOptimizer().minimize(E_loss0, var_list = e_vars + r_vars)\n",
        "  E_solver = tf.train.AdamOptimizer().minimize(E_loss, var_list = e_vars + r_vars)\n",
        "  D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list = d_vars)\n",
        "  G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list = g_vars + s_vars)      \n",
        "  GS_solver = tf.train.AdamOptimizer().minimize(G_loss_S, var_list = g_vars + s_vars)   \n",
        "        \n",
        "  ## Restores TimeGAN training sess   \n",
        "  saver = tf.train.Saver()\n",
        "  sess = tf.Session()\n",
        "  saver.restore(sess, os.path.join(OUTPUT_DIR, 'sess.ckpt'))\n",
        "    \n",
        "  ## Synthetic data generation\n",
        "  Z_mb = random_generator(no, z_dim, ori_time, max_seq_len)\n",
        "  generated_data_curr = sess.run(X_hat, feed_dict={Z: Z_mb, X: ori_data, T: ori_time})    \n",
        "    \n",
        "  generated_data = list()\n",
        "    \n",
        "  for i in range(no):\n",
        "    temp = generated_data_curr[i,:ori_time[i],:]\n",
        "    generated_data.append(temp)\n",
        "        \n",
        "  # Renormalization\n",
        "  generated_data = generated_data * max_val\n",
        "  generated_data = generated_data + min_val\n",
        "    \n",
        "  return generated_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl6HE6jcsdcF",
        "colab_type": "text"
      },
      "source": [
        "## Synthetic Data Generation\n",
        "### Data Loading"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbubwwPCsdcG",
        "colab_type": "code",
        "outputId": "a43d00e4-83cd-4950-e52b-535b75dccd59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from scipy.io import loadmat\n",
        "\n",
        "DATA_DIR = 'data'\n",
        "\n",
        "def MinMaxScaler(data):\n",
        "  numerator = data - np.min(data, 0)\n",
        "  denominator = np.max(data, 0) - np.min(data, 0)\n",
        "  norm_data = numerator / (denominator + 1e-7)\n",
        "  return norm_data\n",
        "\n",
        "def soro_freemotion_data_loading(seq_length, shuffle=True):\n",
        "    data = list()\n",
        "    raw_data = loadmat(os.path.join(DATA_DIR, 'train.mat'))\n",
        "    index = 18000\n",
        "    \n",
        "    _x = np.dstack((raw_data[\"Flex\"][:index], raw_data[\"Force\"][:index], raw_data[\"Pressure\"][:index]))\n",
        "    _x = _x.reshape(-1,3)\n",
        "\n",
        "    x_markers = np.array(raw_data[\"X_markers\"][:index])\n",
        "    y_markers = np.array(raw_data[\"Y_markers\"][:index])\n",
        "\n",
        "    x = np.zeros((_x.shape[0], _x.shape[1] + x_markers.shape[1] + y_markers.shape[1]))\n",
        "    for i in range(len(_x)):\n",
        "        x[i] = np.append(_x[i], (x_markers[i], y_markers[i]))\n",
        "\n",
        "    x = MinMaxScaler(x)\n",
        "    temp_data = []\n",
        "    # Cut data by sequence length WITHOUT overlap\n",
        "    for i in range(0, len(x), seq_length):\n",
        "        _x = x[i:i + seq_length]\n",
        "        temp_data.append(_x)\n",
        "\n",
        "    if shuffle:\n",
        "      # Mix the datasets (to make it similar to i.i.d)\n",
        "      idx = np.random.permutation(len(temp_data))    \n",
        "      data = []\n",
        "      for i in range(len(temp_data)):\n",
        "        data.append(temp_data[idx[i]])\n",
        "    else:\n",
        "      data = temp_data\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A2VigHHsdcJ",
        "colab_type": "text"
      },
      "source": [
        "## Network Parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JHqwl3rsdcJ",
        "colab_type": "code",
        "outputId": "9bbd5705-4d78-4d62-dfbe-908775d449ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "seq_length = 2000\n",
        "parameters = dict()\n",
        "\n",
        "parameters['module'] = 'gru' \n",
        "parameters['hidden_dim'] = 24\n",
        "parameters['num_layer'] = 3\n",
        "parameters['iterations'] = 10000\n",
        "parameters['batch_size'] = 3 # len(dataX) # 1 # 128\n",
        "parameters['z_dim'] = 19 #len(dataX[0][0,:]) \n",
        "print('Parameters are ' + str(parameters))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Zd-qj7sdcM",
        "colab_type": "text"
      },
      "source": [
        "## Generate Synthetic Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cpk-EnysdcM",
        "colab_type": "code",
        "outputId": "42547be8-3fe5-45bb-ab2b-31799d191afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "source": [
        "## Necessary packages\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "OUTPUT_DIR = 'output/new_train_2'\n",
        "\n",
        "## Data loading\n",
        "dataX = soro_freemotion_data_loading(seq_length, False)\n",
        "print('dataset is ready:', np.shape(dataX))\n",
        "\n",
        "# Run TimeGAN\n",
        "timegan_train(dataX, parameters)   \n",
        "print('Finish Synthetic Data Generation')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aHkKZIU_0ut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3c4235a4-1a77-4011-8069-01eaae6e4c2f"
      },
      "source": [
        "parameters = dict()\n",
        "\n",
        "parameters['seq_length'] = 18000  # This will influence the shape of the synthetic data\n",
        "parameters['module'] = 'gru' \n",
        "parameters['hidden_dim'] = 24\n",
        "parameters['num_layer'] = 3\n",
        "parameters['iterations'] = 10000\n",
        "parameters['batch_size'] = 128 # len(dataX) # 1 # 128\n",
        "parameters['z_dim'] = 19 #len(dataX[0][0,:]) \n",
        "print('Parameters are ' + str(parameters))\n",
        "\n",
        "dataX_hat = timegan_generate(parameters)\n",
        "print(dataX_hat.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3B3wmWqAAR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(os.path.join(OUTPUT_DIR, \"synthetic\"), dataX_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "from data_loading import reverse_soro_data_loading\n",
        "\n",
        "print(dataX_hat.shape)\n",
        "dataX = np.array(soro_freemotion_data_loading(18000, False))\n",
        "# dataX = np.reshape(dataX, (-1, 19)) \n",
        "print(dataX.shape)\n",
        "\n",
        "column = 18\n",
        "\n",
        "pyplot.figure()\n",
        "pyplot.subplot(3, 1, 1)\n",
        "pyplot.plot(dataX_hat[0][:, column])\n",
        "pyplot.subplot(3, 1, 2)\n",
        "pyplot.plot(dataX[0][:, column])\n",
        "pyplot.show()\n",
        "pyplot.savefig(os.path.join(OUTPUT_DIR, \"synthetic_plot\"))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}